{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a45abe13",
   "metadata": {},
   "source": [
    "### Desarrollo del codigo principal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87644a7c",
   "metadata": {},
   "source": [
    "##### Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3984c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias prehechas\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015005ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamado a los modelos de autoria propia\n",
    "import cnn\n",
    "import exploracion\n",
    "import resnet50 as res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701e39a3",
   "metadata": {},
   "source": [
    "##### Descarga de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9edf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, info = tfds.load('deep_weeds', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a52348b",
   "metadata": {},
   "source": [
    "##### Almacenamiento por separado de las imagenes y los labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3349c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = dataset['train']\n",
    "\n",
    "X_rgb = []\n",
    "X_gray = []\n",
    "y = []\n",
    "\n",
    "for image, label in tfds.as_numpy(datos):\n",
    "    #tensor = tf.convert_to_tensor(image)\n",
    "    #gray_img = tf.image.rgb_to_grayscale(tensor)\n",
    "\n",
    "    X_rgb.append(image)\n",
    "    #X_gray.append(gray_img.numpy())\n",
    "    y.append(label)\n",
    "\n",
    "del dataset\n",
    "del datos\n",
    "\n",
    "X_rgb = np.array(X_rgb, dtype=np.float32)\n",
    "#X_rgbg = np.concatenate([X_rgb, X_gray], axis=-1)\n",
    "y = np.array(y)\n",
    "\n",
    "#del X_gray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6afc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shapes')\n",
    "print(f'X_rgb: {X_rgb.shape}')\n",
    "#print(f'X_rgbg: {X_rgbg.shape}')\n",
    "print(f'y: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc5a04",
   "metadata": {},
   "source": [
    "##### Reduccion dimensional de las imagenes para optimizar la carga computacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cf5db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducitos tamaño para poder optimizar el uso de memoria\n",
    "X_rgb = tf.convert_to_tensor(X_rgb, dtype=tf.float32)\n",
    "X_rgb = tf.image.resize(X_rgb, [128, 128], method='area')\n",
    "        \n",
    "# Normalizamos las imágenes al rango [0, 1]\n",
    "X_scaled_rgb = (X_rgb / 255.0).numpy()\n",
    "\n",
    "del X_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44820c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reducitos tamaño para poder optimizar el uso de memoria\n",
    "# X_rgbg = tf.convert_to_tensor(X_rgbg, dtype=tf.float32)\n",
    "# X_rgbg = tf.image.resize(X_rgbg, [128, 128], method='area')\n",
    "        \n",
    "# # Normalizamos las imágenes al rango [0, 1]\n",
    "# X_scaled_rgbg = (X_rgbg / 255.0).numpy()\n",
    "\n",
    "# del X_rgbg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab3d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicación de one-hot encoding a las etiquetas\n",
    "y_onehot = np.array(to_categorical(y))\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bb3a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shapes')\n",
    "print(f'X_rgb: {X_scaled_rgb.shape}')\n",
    "#print(f'X_gray: {X_scaled_rgbg.shape}')\n",
    "print(f'y: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d56526",
   "metadata": {},
   "source": [
    "##### Aplicación de las CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a2ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "redConvolucional_rgb = cnn.Propuesta_rgb(X_scaled_rgb, y_onehot)\n",
    "del X_scaled_rgb\n",
    "redConvolucional_rgb.CrearModelo()\n",
    "redConvolucional_rgb.EvaluarModelo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5652ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redConvolucional_rgbgray = cnn.Propuesta_gray(X_scaled_rgbg, y_onehot)\n",
    "# del X_scaled_rgbg\n",
    "# redConvolucional_rgbgray.CrearModelo()\n",
    "# redConvolucional_rgbgray.EvaluarModelo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5423e08c",
   "metadata": {},
   "source": [
    "Observacin de la forma de los modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf44d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo RGB\n",
    "print('Modelo RGB')\n",
    "redConvolucional_rgb.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e232a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Modelo RGB + GRAY\n",
    "# print('Modelo RGB + gray')\n",
    "# redConvolucional_rgbgray.model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
